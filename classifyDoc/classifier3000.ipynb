{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle pdfs, extract text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import torch\n",
    "from transformers import pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_text(file_path):\n",
    "    text = \"\"\n",
    "    with fitz.open(file_path) as pdf:\n",
    "        for page in pdf:\n",
    "            text += page.get_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# credit_agreement_2 = pdf_to_text(\"documents/credit-agreement_2.pdf\")\n",
    "# credit_agreement_1 = pdf_to_text(\"documents/credit_agreement.pdf\")\n",
    "# assumption_agreement = pdf_to_text(\"documents/assumption_agreement.pdf\")\n",
    "# collateral_assignment_li = pdf_to_text(\"documents/collateral_assignment-li.pdf\")\n",
    "# participation_agreement = pdf_to_text(\"documents/participation_agreement.pdf\")\n",
    "\n",
    "credit_agreement_1 = pdf_to_text('documents/credit_agreement.pdf')\n",
    "credit_agreement_2 = pdf_to_text('documents/credit-agreement_2.pdf')\n",
    "assumption_agreement = pdf_to_text('documents/assumption-agreement.pdf')\n",
    "collateral_assignment = pdf_to_text('documents/collateral_assignment-li.pdf')\n",
    "participation_agreement = pdf_to_text('documents/participation_agreement.pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# implement zero-shot learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #loading zero-shot text classification model\n",
    "# classifier = pipeline(model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "# # define the candidate classes\n",
    "# candidate_classes = [credit_agreement_1, credit_agreement_2, assumption_agreement, collateral_assignment, participatio_agreement]\n",
    "\n",
    "# document = \"This is a credit agreement\"\n",
    "\n",
    "# # Chunking document into smaller parts\n",
    "# chunk_size = 500  # You can adjust this based on the model's sequence length limit\n",
    "# chunks = [document[i:i+chunk_size] for i in range(0, len(document), chunk_size)]\n",
    "\n",
    "# results = []\n",
    "# for chunk in chunks:\n",
    "#     # Perform zero-shot classification on each chunk\n",
    "#     result = classifier(chunk, candidate_classes)\n",
    "#     results.append(result)\n",
    "# # perform zero-shot classification\n",
    "\n",
    "# for result in results:\n",
    "# # print the predicted label and associated confidence\n",
    "#     print(result['labels'][0])\n",
    "#     print[result['scores'][0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Collateral Assignment', 0.30664098262786865)\n",
      "('Collateral Assignment', 0.38002437353134155)\n",
      "('Credit Agreement', 0.9147555828094482)\n",
      "('Participation Agreement', 0.29795587062835693)\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "labels = [\"Assumption Agreement\", \"Collateral Assignment\", \"Credit Agreement\", \"Participation Agreement\"]\n",
    "\n",
    "def classify_text(text, labels):\n",
    "    result = classifier(text, candidate_labels=labels)\n",
    "    return result['labels'][0], result['scores'][0]\n",
    "\n",
    "# Classify the extracted texts\n",
    "label_assumption_agreement = classify_text(assumption_agreement, labels)\n",
    "label_collateral_assignment = classify_text(collateral_assignment, labels)\n",
    "# label_credit_agreement = classify_text(credit_agreement_1, labels)\n",
    "label_credit_agreement_2 = classify_text(credit_agreement_2, labels)\n",
    "label_participation_agreement = classify_text(participation_agreement, labels)\n",
    "\n",
    "print(label_assumption_agreement)\n",
    "print(label_collateral_assignment)\n",
    "# print(label_credit_agreement)\n",
    "print(label_credit_agreement_2)\n",
    "print(label_participation_agreement)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
